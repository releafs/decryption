name: Image Processing Pipeline

on:
  push:
    branches:
      - main
    paths:
      - 'decryption/input/**'  # Trigger when a file is pushed to 'decryption/input/'

jobs:
  process-images:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        file_batch: [batch1, batch2, batch3]  # Example for parallel processing
    permissions:
      contents: write  # Allow pushing changes to the repository

    steps:
    # Step 1: Check out the repository
    - name: Checkout Repository
      uses: actions/checkout@v4
      with:
        persist-credentials: true  # Ensure Git credentials are available

    # Step 2: Set up caching for Python dependencies
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    # Step 3: Set up Python environment
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.x'

    # Step 4: Install dependencies (only if not cached)
    - name: Install Dependencies
      run: |
        pip install -r requirements.txt

    # Step 5: Ensure the input directory exists before running any scripts
    - name: Create input directory if missing
      run: mkdir -p decryption/input  # Create the input directory if it doesn't exist

    # Step 6: Run script1.py, script2.py, and script3.py in parallel for different batches of files
    - name: Run script1.py for batch1
      if: matrix.file_batch == 'batch1'
      run: python scripts/script1.py

    - name: Run script2.py for batch2
      if: matrix.file_batch == 'batch2'
      run: python scripts/script2.py

    - name: Run script3.py for batch3
      if: matrix.file_batch == 'batch3'
      run: python scripts/script3.py

    # Step 7: Debugging - Print generated files and their contents
    - name: List files and display contents in process directory before upload
      run: |
        ls -la process/
        echo "Contents of decrypted_data_with_binary.csv:"
        cat process/decrypted_data_with_binary.csv
        echo "Contents of merged_data_with_metadata.csv:"
        cat process/merged_data_with_metadata.csv

    # Step 8: Verify if the output file exists
    - name: Verify output file exists
      run: |
        if [ ! -f "process/merged_data_with_metadata.csv" ]; then
          echo "Output file not found!"
          exit 1
        else
          echo "Output file found!"
        fi

    # Step 9: Commit and push processed result to the repository
    - name: Commit and push processed result
      if: matrix.file_batch == 'batch1'  # Only do this for one batch to avoid duplicate commits
      run: |
        git config --global user.email "action@github.com"
        git config --global user.name "GitHub Action"
        git add process/merged_data_with_metadata.csv
        git commit -m "Add processed result for ${{ github.sha }}"
        git push

    # Step 10: Run script4.py to delete PNG files
    - name: Delete Uploaded PNGs
      run: python scripts/script4.py

    # Step 11: Clean up process directory
    - name: Clean up process directory
      run: rm -rf process/*
